- Implement option to load directly all kernel parameters and store them easily in the kernel class: read and write
- Review partitioning during prediction. We seem to be having memory problem after fitting.
  v1.08 seems to have some problems not building the whole matrix for prediction 
  and new version 1.11 does support partitioning in multiple GPUs anymore
- We can also try to empty memory after having maximized the marginal likelihood just in case -> doesn't work
- Study more pytorch memory usage 
- Use ProductKernel class for our product kernels
- Move to KeOps Kernels for partitioning in gpytorch 1.11 on single GPUs