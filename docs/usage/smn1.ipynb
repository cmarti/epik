{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'epik'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6d36ac3492b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_kernel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScaleKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mepik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTEST_DATA_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mepik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSkewedVCKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mepik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEpiK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'epik'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from gpytorch.kernels.rbf_kernel import RBFKernel\n",
    "from gpytorch.kernels.scale_kernel import ScaleKernel\n",
    "\n",
    "from epik.src.settings import TEST_DATA_DIR\n",
    "from epik.src.kernel import SkewedVCKernel\n",
    "from epik.src.model import EpiK\n",
    "from scipy.stats.stats import pearsonr\n",
    "from epik.src.utils import seq_to_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/grid/mccandlish/home_norepl/martigo/programs/epik/docs/usage',\n",
       " '/cm/local/apps/python37/lib/python37.zip',\n",
       " '/cm/local/apps/python37/lib/python3.7',\n",
       " '/cm/local/apps/python37/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/gpmap_tools-0.1.0-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/numpy-1.21.5-py3.7-linux-x86_64.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/scipy-1.7.3-py3.7-linux-x86_64.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/tqdm-4.63.0-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/matplotlib-3.5.1-py3.7-linux-x86_64.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/seaborn-0.11.2-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/logomaker-0.8-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/plotly-5.6.0-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/holoviews-1.15.1a1-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/biopython-1.79-py3.7-linux-x86_64.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/fonttools-4.37.1-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/tenacity-8.0.1-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/pyviz_comms-2.2.1-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/panel-0.14.0a8-py3.7.egg',\n",
       " '/grid/mccandlish/home_norepl/martigo/.local/lib/python3.7/site-packages/Markdown-3.4.1-py3.7.egg',\n",
       " '/grid/it/data/elzar/easybuild/software/Anaconda3/2020.02/lib/python3.7/site-packages',\n",
       " '/cm/local/apps/python37/lib/python3.7/site-packages',\n",
       " '/cm/local/apps/uge/var/jupyterhub/batchspawner-master',\n",
       " '/grid/it/data/elzar/easybuild/software/Anaconda3/2020.02/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/grid/mccandlish/home_norepl/martigo/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "output_device = torch.device('cuda:0')\n",
    "n_devices, output_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3274207757.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_623041/3274207757.py\"\u001b[0;36m, line \u001b[0;32m80\u001b[0m\n\u001b[0;31m    rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def calc_L_polynomial_coeffs():\n",
    "        lambdas = np.array([q**k for k in range(l+1)])\n",
    "        s = l + 1\n",
    "        B = np.zeros((s, s))\n",
    "        idx = np.arange(s)\n",
    "        for k in idx:\n",
    "            k_idx = idx != k\n",
    "            k_lambdas = lambdas[k_idx]\n",
    "            norm_factor = 1 / np.prod(k_lambdas - lambdas[k])\n",
    "\n",
    "            for power in idx:\n",
    "                p = np.sum([np.product(v) for v in combinations(k_lambdas, l - power)])\n",
    "                B[power, k] = norm_factor * (-1) ** (power) * p\n",
    "        return(B)\n",
    "\n",
    "\n",
    "# custom kernel for DNA sequences\n",
    "class CustomKernel(gpytorch.kernels.kernel.Kernel):\n",
    "    is_stationary = True\n",
    "    def __init__(self, alpha, l,train_p=True, q=0.7,\n",
    "                log_lda_prior=None, log_lda_constraint=None, \n",
    "                log_p_prior=None, log_p_constraint=None,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.odds = torch.nn.Parameter(torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]), requires_grad=False)\n",
    "        self.scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)])\n",
    "        self.scaling_factors[0] = 1\n",
    "        self.scaling_factors = torch.nn.Parameter(self.scaling_factors, requires_grad=False)\n",
    "        \n",
    "        self.coeffs = torch.tensor(calc_L_polynomial_coeffs(), dtype=torch.float32)\n",
    "        self.coeffs = torch.nn.Parameter(self.coeffs, requires_grad=False)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "          name='raw_log_p', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l, alpha), requires_grad=train_p)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "          name='raw_log_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l+1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if log_lda_constraint is None:\n",
    "          log_lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        if log_p_constraint is None:\n",
    "          log_p_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_log_lda\", log_lda_constraint)\n",
    "        self.register_constraint(\"raw_log_p\", log_p_constraint)\n",
    "\n",
    "    @property\n",
    "    def log_lda(self):\n",
    "      return self.raw_log_lda_constraint.transform(self.raw_log_lda)\n",
    "\n",
    "    @property\n",
    "    def log_p(self):\n",
    "      return self.raw_log_p_constraint.transform(self.raw_log_p)\n",
    "\n",
    "    @log_lda.setter\n",
    "    def log_lda(self, value):\n",
    "      return self._set_log_lda(value)\n",
    "\n",
    "    @log_p.setter\n",
    "    def log_p(self, value):\n",
    "      return self._set_log_p(value)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "        \n",
    "        log_p = self.log_p - torch.logsumexp(self.log_p, 1)\n",
    "        ps = torch.exp(log_p)\n",
    "        Dpi = torch.diag(torch.exp(x2.matmul(torch.flatten(log_p)))\n",
    "        \n",
    "        rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*self.scaling_factors\n",
    "        \n",
    "        weights = torch.matmul(self.coeffs, torch.exp(self.log_lda))\n",
    "        \n",
    "        k = torch.sum(torch.mul(powers, weights), -1)\n",
    "                \n",
    "        return k\n",
    "\n",
    "    \n",
    "class SkewVCModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ker):\n",
    "        super(SkewVCModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        base_covar_module = ker\n",
    "\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grid/it/data/elzar/easybuild/software/Anaconda3/2020.02/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "alpha = 4\n",
    "l = 7\n",
    "q = 0.7\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/davidmccandlish/vcregression/master/vcregression/data/Smn1/smn1data.csv\n",
    "  \n",
    "import pandas as pd\n",
    "dat = pd.read_csv(\"smn1data.csv\", header=None)\n",
    "dat = dat.rename(columns={0:\"seq\", 1:\"psi\", 2:\"std\", 3:\"gene\"})\n",
    "dat['seq']=[seq[:3] + seq[4:] for seq in dat['seq']]\n",
    "\n",
    "from collections import OrderedDict\n",
    "IUPAC_VOCAB_ = OrderedDict([\n",
    "    (\"A\", 0),\n",
    "    (\"U\", 1),\n",
    "    (\"C\", 2),\n",
    "    (\"G\", 3)])\n",
    "\n",
    "def tokenize(seq):\n",
    "    return [IUPAC_VOCAB_[char] for char in seq]\n",
    "\n",
    "seqs = [tokenize(seq) for seq in dat.seq]\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n",
    "y = torch.tensor(dat.psi, dtype=torch.float32).to(output_device)\n",
    "\n",
    "\n",
    "# train test data\n",
    "import random\n",
    "train_size = 10000\n",
    "train_ids = random.sample(range(len(seqs1h)), train_size)\n",
    "test_ids = random.sample(list(set(range((len(seqs1h)))).difference(train_ids)), dat.shape[0] - train_size)\n",
    "\n",
    "train_x, test_x = seqs1h[train_ids], seqs1h[test_ids]\n",
    "train_y, test_y = y[train_ids], y[test_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AAAAAAA\n",
       "1        AAAAAAC\n",
       "2        AAAAAAG\n",
       "3        AAAAAAU\n",
       "4        AAAAACA\n",
       "          ...   \n",
       "30727    UUUUUGU\n",
       "30728    UUUUUUA\n",
       "30729    UUUUUUC\n",
       "30730    UUUUUUG\n",
       "30731    UUUUUUU\n",
       "Name: seq, Length: 30732, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_623041/657227798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_noise, \n\u001b[1;32m      5\u001b[0m                                                                learn_additional_noise=True).to(output_device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define likelihood\n",
    "train_noise = np.array(dat['std'].iloc[train_ids])**2\n",
    "train_noise = torch.tensor(train_noise, dtype=torch.float32).to(output_device)\n",
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_noise, \n",
    "                                                               learn_additional_noise=True).to(output_device)\n",
    "# Define model\n",
    "kernel = CustomKernel(alpha, l, train_p=True)\n",
    "kernel.raw_log_lda = torch.nn.Parameter(torch.cat((torch.tensor([-100.]), \n",
    "                                                   -2*torch.arange(l))).to(output_device))\n",
    "model = SkewVCModel(train_x, train_y, likelihood, kernel).to(output_device)\n",
    "\n",
    "# predicting for test points using partitioning\n",
    "checkpoint_size = train_x.shape[0]//2\n",
    "\n",
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.beta_features.checkpoint_kernel(checkpoint_size):\n",
    "    f_preds = model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemMonitor():\n",
    "    def __init__(self):\n",
    "        self.history = [0]\n",
    "    \n",
    "    def __call__(self):\n",
    "        m = torch.cuda.memory_allocated() / 2**20\n",
    "        print('Total usage {:.2f}MB; since last: {:.2f}MB'.format(m, m - self.history[0]))\n",
    "        self.history.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11185.01MB; since last: 11185.01MB\n"
     ]
    }
   ],
   "source": [
    "monitor = MemMonitor()\n",
    "monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11185.01MB; since last: 11185.01MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 28]), torch.Size([1000, 28]), None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct masks used for calculate rates\n",
    "x1, x2 = train_x[:1000, :], train_x[:1000, :]\n",
    "x1.shape, x2.shape, monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11185.01MB; since last: 11185.01MB\n"
     ]
    }
   ],
   "source": [
    "torch.unsqueeze(x1, 1).shape, x1.shape\n",
    "monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0, 0, :], x1[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11291.82MB; since last: 11291.82MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([1000, 1000, 28]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "monitor(), masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11291.74MB; since last: 11291.74MB\n"
     ]
    }
   ],
   "source": [
    "ps = torch.softmax(torch.rand(l, alpha).to(output_device), axis=1)\n",
    "ps\n",
    "monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage 11295.77MB; since last: 11295.77MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([1000, 28]), torch.Size([28]), torch.Size([1000]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dpi = torch.diag(torch.exp(x2.matmul(torch.log(torch.flatten(ps)))))\n",
    "monitor(), x2.shape, torch.flatten(ps).shape, log_pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "rates = rates/ps\n",
    "rates = torch.flatten(rates, start_dim=1)\n",
    "log_rates = torch.log(rates)\n",
    "\n",
    "out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "out = torch.flatten(out, start_dim=3)\n",
    "\n",
    "powers_nz = torch.exp(torch.sum(out, -1))\n",
    "power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "powers = powers*self.scaling_factors\n",
    "\n",
    "weights = torch.matmul(self.coeffs, torch.exp(self.log_lda))\n",
    "\n",
    "k = torch.sum(torch.mul(powers, weights), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpmap",
   "language": "python",
   "name": "gpmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
